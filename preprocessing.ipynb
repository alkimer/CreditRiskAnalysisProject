{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN41JN7hkgZj"
      },
      "source": [
        "# Binary Categorical Variables Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-ypcfQkk1r9",
        "outputId": "c3319a62-9434-482d-d991-0397cea89460"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop\")  # change to your actual project root folder\n",
        "print(\"Current dir:\", os.getcwd())  # confirm\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_svK6iAVXha8",
        "outputId": "31c45142-0159-4a45-c67a-cc29257da7bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current dir: /content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from processing.process_categorical_binary import clean_all_binary\n",
        "from processing.process_categorical_multicategorical import clean_all_multi\n",
        "from processing.process_numerical_continuous import process_numerical_continuous_split\n",
        "from processing.process_numerical_discrete import process_numerical_discrete\n",
        "from processing.smote_oversampling import apply_smote\n",
        "from processing.process_all_features import process_all\n",
        "\n"
      ],
      "metadata": {
        "id": "bjZ56H-wOJ6c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from processing.process_all_features import process_all\n",
        "path_train= \"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/data_splitted/X_train.csv\"\n",
        "path_val= \"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/data_splitted/X_val.csv\"\n",
        "\n",
        "path_y_train = \"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/data_splitted/y_train.csv\"\n",
        "path_y_val   = \"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/data_splitted/y_val.csv\"\n",
        "\n",
        "X_train_output=\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/processed/X_train_p.csv\"\n",
        "X_val_output=\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/processed/X_val_p.csv\"\n",
        "\n",
        "\n",
        "process_all(path_train, path_val, X_train_output, X_val_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABT78FxbZ_gf",
        "outputId": "42f58a75-d568-4771-be33-e32b3708d7a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The following are the binary categrorical variables\n",
            "in the dataset (first their original indexes):\n",
            "\n",
            "[3, 6, 16, 21, 24, 25, 28, 33, 37]\n",
            "['APPLICATION_SUBMISSION_TYPE', 'SEX', 'FLAG_RESIDENCIAL_PHONE', 'FLAG_EMAIL', 'FLAG_VISA', 'FLAG_MASTERCARD', 'FLAG_OTHER_CARDS', 'COMPANY', 'FLAG_PROFESSIONAL_PHONE']\n",
            "\n",
            "////////////////////\n",
            "\n",
            "\n",
            "Variable: APPLICATION_SUBMISSION_TYPE \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: SEX \n",
            "\n",
            "Null or empty values in TRAIN. It's time to clean\n",
            "Null or empty values in VAL. It's time to clean\n",
            "Original train length: 40000\n",
            "Cleaned train length: 40000\n",
            "Original val length: 10000\n",
            "Cleaned val length: 10000\n",
            "\n",
            "\n",
            "Variable: Cleaned variable SEX \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_RESIDENCIAL_PHONE \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_EMAIL \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_VISA \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_MASTRECARD \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_OTHER_CARDS \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "Variable: FLAG_PROFESSIONAL_PHONE \n",
            "\n",
            "Train OK. Continue!\n",
            "Val OK. Continue!\n",
            "\n",
            "\n",
            "--- End of the categorical binary variables processing ---\n",
            "\n",
            "\n",
            "‚úÖ Variables de ubicaci√≥n multicateg√≥ricas procesadas correctamente.\n",
            "‚úÖ Target encoding aplicado a PAYMENT_DAY_CAT.\n",
            "‚úÖ Target encoding aplicado a MARITAL_STATUS.\n",
            "‚úÖ Target encoding aplicado a QUANT_DEPENDANTS (binned).\n",
            "‚úÖ Target encoding aplicado a MONTHS_IN_RESIDENCE (binned).\n",
            "‚úÖ QUANT_BANKING_ACCOUNTS normalizada con MinMax.\n",
            "‚ÑπÔ∏è QUANT_CARS v√°lida\n",
            "‚úÖ Columna MONTHS_IN_THE_JOB eliminada del DataFrame.\n",
            "‚úÖ Columna EDUCATION_LEVEL eliminada del DataFrame.\n",
            "‚úÖ Columna QUANT_ADDITIONAL_CARDS eliminada del DataFrame.\n",
            "‚úÖ Columna QUANT_SPECIAL_BANKING_ACCOUNTS eliminada del DataFrame.\n",
            "‚úÖ AGE normalizada con MinMax.\n",
            "‚úÖ Columna MATE_PROFESSION_CODE eliminada del DataFrame.\n",
            "‚úÖ Target encoding aplicado a PROFESSION_CODE.\n",
            "‚úÖ Columnas conservadas:\n",
            "['PAYMENT_DAY_TE', 'MARITAL_STATUS_TE', 'QUANT_DEPENDANTS_TE', 'QUANT_CARS_CLEAN', 'MONTHS_IN_RESIDENCE_TE', 'QUANT_BANKING_ACCOUNTS_NORM', 'AGE_NORM', 'PROFESSION_CODE_TE', 'OCCUPATION_TYPE_IMPUTED']\n",
            "\n",
            "üóëÔ∏è Columnas eliminadas:\n",
            "['ID_CLIENT', 'CLERK_TYPE', 'PAYMENT_DAY', 'APPLICATION_SUBMISSION_TYPE', 'POSTAL_ADDRESS_TYPE', 'SEX', 'STATE_OF_BIRTH', 'CITY_OF_BIRTH', 'NACIONALITY', 'RESIDENCIAL_STATE', 'RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH', 'FLAG_RESIDENCIAL_PHONE', 'RESIDENCIAL_PHONE_AREA_CODE', 'RESIDENCE_TYPE', 'MONTHS_IN_RESIDENCE', 'FLAG_MOBILE_PHONE', 'FLAG_EMAIL', 'PERSONAL_MONTHLY_INCOME', 'OTHER_INCOMES', 'FLAG_VISA', 'FLAG_MASTERCARD', 'FLAG_DINERS', 'FLAG_AMERICAN_EXPRESS', 'FLAG_OTHER_CARDS', 'PERSONAL_ASSETS_VALUE', 'COMPANY', 'PROFESSIONAL_STATE', 'PROFESSIONAL_CITY', 'PROFESSIONAL_BOROUGH', 'FLAG_PROFESSIONAL_PHONE', 'PROFESSIONAL_PHONE_AREA_CODE', 'EDUCATION_LEVEL.1', 'FLAG_HOME_ADDRESS_DOCUMENT', 'FLAG_RG', 'FLAG_CPF', 'FLAG_INCOME_PROOF', 'PRODUCT', 'FLAG_ACSP_RECORD', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'TARGET_LABEL_BAD', 'PAYMENT_DAY_CAT', 'MARITAL_STATUS_CAT', 'QUANT_DEPENDANTS_BIN', 'MONTHS_IN_RESIDENCE_IMPUTED', 'MONTHS_IN_RESIDENCE_BIN', 'PROFESSION_CODE_IMPUTED', 'PROFESSION_CODE_CAT']\n",
            "\n",
            "‚úÖ Preprocesamiento finalizado. Vista general del DataFrame:\n",
            "  PAYMENT_DAY_TE MARITAL_STATUS_TE QUANT_DEPENDANTS_TE  QUANT_CARS_CLEAN  \\\n",
            "0       0.231357          0.219235            0.261103                 1   \n",
            "1       0.240511          0.303541            0.261103                 0   \n",
            "2       0.231357          0.303541            0.261103                 0   \n",
            "3       0.231357          0.243772            0.261103                 1   \n",
            "4       0.231357          0.303541            0.261103                 0   \n",
            "\n",
            "  MONTHS_IN_RESIDENCE_TE  QUANT_BANKING_ACCOUNTS_NORM  AGE_NORM  \\\n",
            "0               0.256804                          0.5      0.49   \n",
            "1               0.278008                          0.0      0.17   \n",
            "2               0.266358                          0.0      0.21   \n",
            "3               0.278008                          0.5      0.51   \n",
            "4               0.266358                          0.0      0.44   \n",
            "\n",
            "   PROFESSION_CODE_TE  OCCUPATION_TYPE_IMPUTED  \n",
            "0            0.256920                      0.0  \n",
            "1            0.262846                      2.0  \n",
            "2            0.262846                      2.0  \n",
            "3            0.262846                      2.0  \n",
            "4            0.262846                      1.0  \n",
            "‚úÖ Target encoding aplicado a PAYMENT_DAY_CAT.\n",
            "‚úÖ Target encoding aplicado a MARITAL_STATUS.\n",
            "‚úÖ Target encoding aplicado a QUANT_DEPENDANTS (binned).\n",
            "‚úÖ Target encoding aplicado a MONTHS_IN_RESIDENCE (binned).\n",
            "‚úÖ QUANT_BANKING_ACCOUNTS normalizada con MinMax.\n",
            "‚ÑπÔ∏è QUANT_CARS v√°lida\n",
            "‚úÖ Columna MONTHS_IN_THE_JOB eliminada del DataFrame.\n",
            "‚úÖ Columna EDUCATION_LEVEL eliminada del DataFrame.\n",
            "‚úÖ Columna QUANT_ADDITIONAL_CARDS eliminada del DataFrame.\n",
            "‚úÖ Columna QUANT_SPECIAL_BANKING_ACCOUNTS eliminada del DataFrame.\n",
            "‚úÖ AGE normalizada con MinMax.\n",
            "‚úÖ Columna MATE_PROFESSION_CODE eliminada del DataFrame.\n",
            "‚úÖ Target encoding aplicado a PROFESSION_CODE.\n",
            "‚úÖ Columnas conservadas:\n",
            "['PAYMENT_DAY_TE', 'MARITAL_STATUS_TE', 'QUANT_DEPENDANTS_TE', 'QUANT_CARS_CLEAN', 'MONTHS_IN_RESIDENCE_TE', 'QUANT_BANKING_ACCOUNTS_NORM', 'AGE_NORM', 'PROFESSION_CODE_TE', 'OCCUPATION_TYPE_IMPUTED']\n",
            "\n",
            "üóëÔ∏è Columnas eliminadas:\n",
            "['ID_CLIENT', 'CLERK_TYPE', 'PAYMENT_DAY', 'APPLICATION_SUBMISSION_TYPE', 'POSTAL_ADDRESS_TYPE', 'SEX', 'STATE_OF_BIRTH', 'CITY_OF_BIRTH', 'NACIONALITY', 'RESIDENCIAL_STATE', 'RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH', 'FLAG_RESIDENCIAL_PHONE', 'RESIDENCIAL_PHONE_AREA_CODE', 'RESIDENCE_TYPE', 'MONTHS_IN_RESIDENCE', 'FLAG_MOBILE_PHONE', 'FLAG_EMAIL', 'PERSONAL_MONTHLY_INCOME', 'OTHER_INCOMES', 'FLAG_VISA', 'FLAG_MASTERCARD', 'FLAG_DINERS', 'FLAG_AMERICAN_EXPRESS', 'FLAG_OTHER_CARDS', 'PERSONAL_ASSETS_VALUE', 'COMPANY', 'PROFESSIONAL_STATE', 'PROFESSIONAL_CITY', 'PROFESSIONAL_BOROUGH', 'FLAG_PROFESSIONAL_PHONE', 'PROFESSIONAL_PHONE_AREA_CODE', 'EDUCATION_LEVEL.1', 'FLAG_HOME_ADDRESS_DOCUMENT', 'FLAG_RG', 'FLAG_CPF', 'FLAG_INCOME_PROOF', 'PRODUCT', 'FLAG_ACSP_RECORD', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'TARGET_LABEL_BAD', 'PAYMENT_DAY_CAT', 'MARITAL_STATUS_CAT', 'QUANT_DEPENDANTS_BIN', 'MONTHS_IN_RESIDENCE_IMPUTED', 'MONTHS_IN_RESIDENCE_BIN', 'PROFESSION_CODE_IMPUTED', 'PROFESSION_CODE_CAT']\n",
            "\n",
            "‚úÖ Preprocesamiento finalizado. Vista general del DataFrame:\n",
            "  PAYMENT_DAY_TE MARITAL_STATUS_TE QUANT_DEPENDANTS_TE  QUANT_CARS_CLEAN  \\\n",
            "0       0.225543          0.233520            0.259853                 0   \n",
            "1       0.232883          0.233520            0.254177                 0   \n",
            "2       0.225543          0.189977            0.254177                 0   \n",
            "3       0.319256          0.233520            0.274834                 1   \n",
            "4       0.232883          0.233520            0.254177                 0   \n",
            "\n",
            "  MONTHS_IN_RESIDENCE_TE  QUANT_BANKING_ACCOUNTS_NORM  AGE_NORM  \\\n",
            "0               0.251154                          0.0  0.206522   \n",
            "1               0.251154                          0.0  0.413043   \n",
            "2               0.232301                          0.0  0.695652   \n",
            "3               0.239837                          0.5  0.358696   \n",
            "4               0.267200                          0.0  0.369565   \n",
            "\n",
            "   PROFESSION_CODE_TE  OCCUPATION_TYPE_IMPUTED  \n",
            "0            0.264824                      5.0  \n",
            "1            0.264824                      2.0  \n",
            "2            0.264824                      1.0  \n",
            "3            0.264824                      2.0  \n",
            "4            0.199214                      2.0  \n",
            "\n",
            "\n",
            "--- END OF THE WHOLE VARIABLES PROCESSING ---\n",
            "\n",
            "\n",
            "\n",
            "Binary Variables Kept//\n",
            "\n",
            "APPLICATION_SUBMISSION_TYPE\n",
            "                        SEX\n",
            "     FLAG_RESIDENCIAL_PHONE\n",
            "                 FLAG_EMAIL\n",
            "                  FLAG_VISA\n",
            "            FLAG_MASTERCARD\n",
            "           FLAG_OTHER_CARDS\n",
            "    FLAG_PROFESSIONAL_PHONE\n",
            "\n",
            "\n",
            "Multicategorical Variables Kept//\n",
            "\n",
            "              STATE_OF_BIRTH\n",
            "           RESIDENCIAL_STATE\n",
            "              RESIDENCE_TYPE\n",
            "          PROFESSIONAL_STATE\n",
            "                 NACIONALITY\n",
            "                     PRODUCT\n",
            "               CITY_OF_BIRTH\n",
            "            RESIDENCIAL_CITY\n",
            "         RESIDENCIAL_BOROUGH\n",
            " RESIDENCIAL_PHONE_AREA_CODE\n",
            "PROFESSIONAL_PHONE_AREA_CODE\n",
            "           RESIDENCIAL_ZIP_3\n",
            "          PROFESSIONAL_ZIP_3\n",
            "\n",
            "\n",
            "Continuous Variables Kept//\n",
            "\n",
            "PERSONAL_MONTHLY_INCOME\n",
            "          OTHER_INCOMES\n",
            "  PERSONAL_ASSETS_VALUE\n",
            "\n",
            "\n",
            "Discrete Variables Kept//\n",
            "\n",
            "           PAYMENT_DAY\n",
            "        MARITAL_STATUS\n",
            "      QUANT_DEPENDANTS\n",
            "            QUANT_CARS\n",
            "   MONTHS_IN_RESIDENCE\n",
            "QUANT_BANKING_ACCOUNTS\n",
            "                   AGE\n",
            "       PROFESSION_CODE\n",
            "       OCCUPATION_TYPE\n",
            "\n",
            "Original # of columns: 53\n",
            "Number of processed VARIABLES: 33\n",
            "Number of dropped columns: 20\n",
            "Number of output columns: 124\n",
            "\n",
            "//  SHAPES OF THE OUTPUT DATASETS  //\n",
            "\n",
            "(X_train_p), (X_val_p)\n",
            "\n",
            "(40000, 124), (10000, 124)\n",
            "\n",
            "Binary, Multicategorical, Continuous, Discrete\n",
            "Train | Val\n",
            "(40000, 8) (10000, 8)\n",
            "(40000, 104) (10000, 104)\n",
            "(40000, 3) (10000, 3)\n",
            "(40000, 9) (10000, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar data balanceada"
      ],
      "metadata": {
        "id": "O6O7BuK5smpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load y_train after SMOTE\n",
        "y_train_smote = pd.read_csv(\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/processed/y_train_smote.csv\")\n",
        "\n",
        "# Flatten if it's a DataFrame with one column\n",
        "if y_train_smote.shape[1] == 1:\n",
        "    y_train_smote = y_train_smote.iloc[:, 0]\n"
      ],
      "metadata": {
        "id": "pVXy0pt5piFf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_smote.value_counts()\n"
      ],
      "metadata": {
        "id": "JJxVgB4qpiJ0",
        "outputId": "246fd214-8cc5-475a-dfad-a7841918fd33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "1    29524\n",
              "0    29524\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "X7SAmTAEsGsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg =None\n",
        "X_train_resampled = pd.read_csv(\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/processed/X_train_p_smote.csv\")\n",
        "y_train_smote = pd.read_csv(\"/content/drive/My Drive/Learning/AnyoneAI/Final_Project/CreditRiskAnalysisProject-develop/data/processed/y_train_smote.csv\").squeeze()\n",
        "\n",
        "# Train logistic regression\n",
        "log_reg = LogisticRegression(solver='saga', max_iter=1000)\n",
        "log_reg.fit(X_train_resampled, y_train_smote)"
      ],
      "metadata": {
        "id": "HXyRxJyvsFQc",
        "outputId": "94408829-9829-486d-8a4d-90b968665ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1630492564>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "risk",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}