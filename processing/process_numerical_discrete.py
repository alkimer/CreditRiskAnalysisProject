import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)


def process_payment_day(df, encode=False):
    """
    La proporci√≥n de deudores no var√≠a seg√∫n el payment day, salvo el d√≠a 25 que tiene una proporci√≥n levemente
    superior de deudores
    Procesa PAYMENT_DAY:
    - Si encode=False: la convierte en categor√≠a (PAYMENT_DAY_CAT). XGboost, LightGBM, RandomForest
    - Si encode=True: adem√°s aplica target encoding (PAYMENT_DAY_TE). Para modelos lineales, logistic regression
    """
    df = df.copy()

    # Convertir a categ√≥rica
    df["PAYMENT_DAY_CAT"] = df["PAYMENT_DAY"].astype("category")

    df.rename(columns={"TARGET_LABEL_BAD=1": "TARGET_LABEL_BAD"}, inplace=True)

    if encode:
        df["PAYMENT_DAY_TE"] = df["PAYMENT_DAY_CAT"].map(
            df.groupby("PAYMENT_DAY_CAT")["TARGET_LABEL_BAD"].mean()
        )
        print("‚úÖ Target encoding aplicado a PAYMENT_DAY_CAT.")
    else:
        print("‚ÑπÔ∏è PAYMENT_DAY convertido en categ√≥rica.")

    return df


def process_marital_status(df, encode=False):
    """
    Preprocesa la columna MARITAL_STATUS:
    - Convierte a categor√≠a
    - Si encode=True, aplica target encoding
    """
    df = df.copy()
    df["MARITAL_STATUS_CAT"] = df["MARITAL_STATUS"].astype("category")

    if encode:
        df["MARITAL_STATUS_TE"] = df["MARITAL_STATUS_CAT"].map(
            df.groupby("MARITAL_STATUS_CAT")["TARGET_LABEL_BAD"].mean()
        )
        print("‚úÖ Target encoding aplicado a MARITAL_STATUS.")
    else:
        print("‚ÑπÔ∏è MARITAL_STATUS convertido en categ√≥rica.")
    df.drop(columns=["MARITAL_STATUS"], inplace=True)

    return df


def process_quant_dependants(df, encode=True, trim_max=6, binning=True):

    """
    Luego del trimming y binning se ve claramente que a mayor cantidad de dependientes
    major cantidad de deudores.

    Preprocesa QUANT_DEPENDANTS:
    - Si binning=False: trunca valores extremos a trim_max (por defecto 6)
    - Si binning=True: agrupa en categor√≠as "0", "1‚Äì3", "4+"
    - Si encode=True, aplica target encoding
    """
    df = df.copy()

    if binning:
        def categorizar_dependants(x):
            if x == 0:
                return "0"
            elif 1 <= x <= 3:
                return "1-3"
            else:
                return "4+"

        df["QUANT_DEPENDANTS_BIN"] = df["QUANT_DEPENDANTS"].apply(categorizar_dependants).astype("category")

        if encode:
            df["QUANT_DEPENDANTS_TE"] = df["QUANT_DEPENDANTS_BIN"].map(
                df.groupby("QUANT_DEPENDANTS_BIN")["TARGET_LABEL_BAD"].mean()
            )
            print("‚úÖ Target encoding aplicado a QUANT_DEPENDANTS (binned).")
        else:
            print("‚ÑπÔ∏è QUANT_DEPENDANTS agrupado en categor√≠as '0', '1‚Äì3', '4+'.")

    else:
        df["QUANT_DEPENDANTS_TRIM"] = df["QUANT_DEPENDANTS"].clip(upper=trim_max)

        if encode:
            df["QUANT_DEPENDANTS_TE"] = df["QUANT_DEPENDANTS_TRIM"].map(
                df.groupby("QUANT_DEPENDANTS_TRIM")["TARGET_LABEL_BAD"].mean()
            )
            print(f"‚úÖ Target encoding aplicado a QUANT_DEPENDANTS (truncado a {trim_max}).")
        else:
            print(f"‚ÑπÔ∏è QUANT_DEPENDANTS truncado a m√°ximo {trim_max}.")

    df.drop(columns=["QUANT_DEPENDANTS"], inplace=True)

    return df


def process_months_in_residence(df, encode=False, binning=True):

    """
    Preprocesa MONTHS_IN_RESIDENCE:
    distribuci√≥n muy sesgada a la izq, y varios nulos.
    Le dejamos el binning en True por default dado que refleja mejor la relaci√≥n con la morosidad
    imputamos la mediana a los nulos
    CREA COLUMNAS :MONTHS_IN_RESIDENCE_BIN Y MONTHS_IN_RESIDENCE_IMPUTED
    - Imputa nulos con la mediana (6)
    - Si binning=True: agrupa en rangos
    - Si encode=True: aplica target encoding
    """
    df = df.copy()

    # Imputar nulos con la mediana
    mediana = df["MONTHS_IN_RESIDENCE"].median()
    df["MONTHS_IN_RESIDENCE_IMPUTED"] = df["MONTHS_IN_RESIDENCE"].fillna(mediana)

    if binning:
        def categorizar_mes(x):
            if x == 0:
                return "0"
            elif 1 <= x <= 5:
                return "1-5"
            elif 6 <= x <= 11:
                return "6-11"
            elif 12 <= x <= 23:
                return "12-23"
            else:
                return "24+"

        df["MONTHS_IN_RESIDENCE_BIN"] = df["MONTHS_IN_RESIDENCE_IMPUTED"].apply(categorizar_mes).astype("category")

        if encode:
            df["MONTHS_IN_RESIDENCE_TE"] = df["MONTHS_IN_RESIDENCE_BIN"].map(
                df.groupby("MONTHS_IN_RESIDENCE_BIN")["TARGET_LABEL_BAD"].mean()
            )
            print("‚úÖ Target encoding aplicado a MONTHS_IN_RESIDENCE (binned).")
        else:
            print("‚ÑπÔ∏è MONTHS_IN_RESIDENCE imputado y binned en categor√≠as.")
    else:
        if encode:
            df.drop(columns=["MONTHS_IN_RESIDENCE"], inplace=True)

            df["MONTHS_IN_RESIDENCE_TE"] = df["MONTHS_IN_RESIDENCE_IMPUTED"].map(
                df.groupby("MONTHS_IN_RESIDENCE_IMPUTED")["TARGET_LABEL_BAD"].mean()
            )
            print("‚úÖ Target encoding aplicado a MONTHS_IN_RESIDENCE (imputado, sin binning).")
        else:
            print("‚ÑπÔ∏è MONTHS_IN_RESIDENCE imputado sin binning.")


    return df



def process_quant_banking_accounts(df, normalize=False):

    """
    Si bien no se especifica exactamente qu√© es , todo parece indicar que refleja cantidades, por lo tanto
    la tratamos como num√©rica discreta.

    Preprocesa QUANT_BANKING_ACCOUNTS como cantidad num√©rica discreta.
    - No requiere imputaci√≥n
    - Si normalize=True: aplica MinMax normalization
    """
    df = df.copy()

    if normalize:
        min_val = df["QUANT_BANKING_ACCOUNTS"].min()
        max_val = df["QUANT_BANKING_ACCOUNTS"].max()
        df["QUANT_BANKING_ACCOUNTS_NORM"] = (df["QUANT_BANKING_ACCOUNTS"] - min_val) / (max_val - min_val)
        df.drop(columns=["QUANT_BANKING_ACCOUNTS"], inplace=True)

        print("‚úÖ QUANT_BANKING_ACCOUNTS normalizada con MinMax.")
    else:
        print("‚ÑπÔ∏è QUANT_BANKING_ACCOUNTS mantenida como cantidad discreta sin normalizar.")

    return df


def process_quant_cars(df):
    """
    - No hace binning, imputaci√≥n ni encoding.
    - solo valida que sea entero
    """
    df = df.copy()
    df["QUANT_CARS_CLEAN"] = df["QUANT_CARS"].astype(int)
    print("‚ÑπÔ∏è QUANT_CARS v√°lida")
    df.drop(columns=["QUANT_CARS"], inplace=True)

    return df


def process_months_in_the_job(df):
    """
    Elimina la columna MONTHS_IN_THE_JOB si existe en el DataFrame.
    El 99% de los casos son cero , por lo tanto no es representativa.
    """
    df = df.copy()

    if "MONTHS_IN_THE_JOB" in df.columns:
        df.drop(columns=["MONTHS_IN_THE_JOB"], inplace=True)
        print("‚úÖ Columna MONTHS_IN_THE_JOB eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna MONTHS_IN_THE_JOB no existe en el DataFrame.")

    return df



def process_education_level(df):
    """
    Elimina la columna EDUCATION_LEVEL si existe en el DataFrame.
    El 100% de los casos son cero , por lo tanto no es representativa.
    """
    df = df.copy()

    if "EDUCATION_LEVEL" in df.columns:
        df.drop(columns=["EDUCATION_LEVEL"], inplace=True)
        print("‚úÖ Columna EDUCATION_LEVEL eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna EDUCATION_LEVEL no existe en el DataFrame.")

    return df

def process_quant_additional_cards(df):
    """
    Elimina la columna quant_additional_cards si existe en el DataFrame.
    El 100% de los casos son cero, por lo tanto no es representativa.
    """
    df = df.copy()

    if "QUANT_ADDITIONAL_CARDS" in df.columns:
        df.drop(columns=["QUANT_ADDITIONAL_CARDS"], inplace=True)
        print("‚úÖ Columna QUANT_ADDITIONAL_CARDS eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna QUANT_ADDITIONAL_CARDS no existe en el DataFrame.")

    return df

def process_quant_special_banking_accounts(df):
    """
    Elimina la columna QUANT_SPECIAL_BANKING_ACCOUNTS si existe en el DataFrame.
    El 100% de los casos son cero, por lo tanto no es representativa.
    """
    df = df.copy()

    if "QUANT_SPECIAL_BANKING_ACCOUNTS" in df.columns:
        df.drop(columns=["QUANT_SPECIAL_BANKING_ACCOUNTS"], inplace=True)
        print("‚úÖ Columna QUANT_SPECIAL_BANKING_ACCOUNTS eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna QUANT_SPECIAL_BANKING_ACCOUNTS no existe en el DataFrame.")

    return df


def process_age(df, normalize=False):
    """
    Preprocesa la variable AGE como num√©rica continua/discreta.
    - Si normalize=True: aplica MinMax normalization, para regresi√≥n lineal, log√≠stica, MLP
    - Normalize=False : random forest, xgboost , lightgbm
    """
    df = df.copy()

    if normalize:
        min_age = df["AGE"].min()
        max_age = df["AGE"].max()
        df["AGE_NORM"] = (df["AGE"] - min_age) / (max_age - min_age)
        print("‚úÖ AGE normalizada con MinMax.")
    else:
        df["AGE_DISCRETE"] = df["AGE"].astype(int)
        print("‚ÑπÔ∏è AGE conservada como num√©rica discreta.")

    df.drop(columns=["AGE"], inplace=True)

    return df


def process_profession_code(df, encode=False, binning=False):
    """
    15% NULOS, IMPUTAMOS CON LA MODA (EL M√ÅS FRECUENTE)

    Preprocesa PROFESSION_CODE:
    - Imputa nulos con la moda
    - Si binning=True: agrupa valores poco frecuentes como 'OTROS'
    - Si encode=True: aplica target encoding
    """
    df = df.copy()

    # Imputaci√≥n con la moda
    moda = df["PROFESSION_CODE"].mode()[0]
    df["PROFESSION_CODE_IMPUTED"] = df["PROFESSION_CODE"].fillna(moda)

    if binning:
        # Marcar como 'OTROS' los valores poco frecuentes (<100 ocurrencias)
        counts = df["PROFESSION_CODE_IMPUTED"].value_counts()
        valores_comunes = counts[counts >= 100].index
        df["PROFESSION_CODE_BINNED"] = df["PROFESSION_CODE_IMPUTED"].apply(
            lambda x: x if x in valores_comunes else "OTROS"
        ).astype("category")

        if encode:
            df["PROFESSION_CODE_TE"] = df["PROFESSION_CODE_BINNED"].map(
                df.groupby("PROFESSION_CODE_BINNED")["TARGET_LABEL_BAD"].mean()
            )
            print("‚úÖ Target encoding aplicado a PROFESSION_CODE (binned).")
        else:
            print("‚ÑπÔ∏è PROFESSION_CODE binned aplicada.")

    else:
        df["PROFESSION_CODE_CAT"] = df["PROFESSION_CODE_IMPUTED"].astype("category")

        if encode:
            df["PROFESSION_CODE_TE"] = df["PROFESSION_CODE_CAT"].map(
                df.groupby("PROFESSION_CODE_CAT")["TARGET_LABEL_BAD"].mean()
            )
            print("‚úÖ Target encoding aplicado a PROFESSION_CODE.")
        else:
            print("‚ÑπÔ∏è PROFESSION_CODE convertida en categ√≥rica.")

    df.drop(columns=["PROFESSION_CODE"], inplace=True)

    return df


def process_mate_profession_code(df):
    """
    60% de nulos, droppeando
    Elimina la columna MATE_PROFESSION_CODE si existe en el DataFrame.
    """
    df = df.copy()

    if "MATE_PROFESSION_CODE" in df.columns:
        df.drop(columns=["MATE_PROFESSION_CODE"], inplace=True)
        print("‚úÖ Columna MATE_PROFESSION_CODE eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna MATE_PROFESSION_CODE no existe en el DataFrame.")

    return df


def process_education_level(df):
    """
    60% de nulos, droppeando
    Elimina la columna EDUCATION_LEVEL si existe en el DataFrame.
    """
    df = df.copy()

    if "EDUCATION_LEVEL" in df.columns:
        df.drop(columns=["EDUCATION_LEVEL"], inplace=True)
        print("‚úÖ Columna EDUCATION_LEVEL eliminada del DataFrame.")
    else:
        print("‚ÑπÔ∏è La columna EDUCATION_LEVEL no existe en el DataFrame.")

    return df

def process_occupation_type(df, encode=False, binning=False, normalize=False):
    """
    14.6% de nulos, imputamos categor√≠a m√°s frecuente.
    Preprocesamiento para OCCUPATION_TYPE:
    - Imputa nulos con la categor√≠a m√°s frecuente.
    - Si encode=True, aplica OneHotEncoding.
    - binning y normalize est√°n ignorados porque no aplican en este caso.
    """
    df = df.copy()
    most_frequent = df["OCCUPATION_TYPE"].mode()[0]
    df["OCCUPATION_TYPE_IMPUTED"] = df["OCCUPATION_TYPE"].fillna(most_frequent)

    if encode:
        dummies = pd.get_dummies(df["OCCUPATION_TYPE_IMPUTED"], prefix="OCCUPATION_TYPE")
        df = pd.concat([df, dummies], axis=1)

    df = df.drop("OCCUPATION_TYPE", axis=1)

    return df


def process_numerical_discrete(csv_path, encode=False, binning=True, normalize=False):
    """
    Abre un archivo CSV y realiza el preprocesamiento completo de variables num√©ricas/discretas
    usando funciones previamente definidas. Controla encoding, binning, normalizaci√≥n y trimming.
    """
    df = pd.read_csv(csv_path, low_memory=False)

    df = process_payment_day(df, encode=encode)
    df = process_marital_status(df, encode=encode)
    df = process_quant_dependants(df, encode=encode, trim_max=6, binning=binning)
    df = process_months_in_residence(df, encode=encode, binning=binning)
    df = process_quant_banking_accounts(df, normalize=normalize)
    df = process_quant_cars(df)
    df = process_months_in_the_job(df)
    df = process_education_level(df)
    df = process_quant_additional_cards(df)
    df = process_quant_special_banking_accounts(df)
    df = process_age(df, normalize=normalize)
    df = process_mate_profession_code(df)
    df = process_profession_code(df, encode=encode)
    df = process_occupation_type(df)


    df = seleccionar_columnas(df)
    print("\n‚úÖ Preprocesamiento finalizado. Vista general del DataFrame:")
    print(df.head())

    return df

def seleccionar_columnas(df):
    reglas = [
        ("PAYMENT_DAY_TE", ["PAYMENT_DAY_CAT"]),
        ("MARITAL_STATUS_TE", ["MARITAL_STATUS_CAT"]),
        ("QUANT_DEPENDANTS_TE", ["QUANT_DEPENDANTS_BIN", "QUANT_DEPENDANTS_TRIM"]),
        ("QUANT_CARS_CLEAN", []),

        ("MONTHS_IN_RESIDENCE_TE", ["MONTHS_IN_RESIDENCE_BIN", "MONTHS_IN_RESIDENCE_IMPUTED"]),
        ("QUANT_BANKING_ACCOUNTS_NORM", ["QUANT_BANKING_ACCOUNTS"]),
        ("AGE_NORM", ["AGE_DISCRETE"]),
        ("PROFESSION_CODE_TE", ["PROFESSION_CODE_BINNED", "PROFESSION_CODE_CAT"]),
        ("OCCUPATION_TYPE_IMPUTED", []),
    ]

    columnas_finales = []
    columnas_descartadas = []

    for preferida, alternativas in reglas:
        if preferida in df.columns:
            columnas_finales.append(preferida)
        else:
            encontrada = False
            for alt in alternativas:
                if alt in df.columns:
                    columnas_finales.append(alt)
                    encontrada = True
                    break
            if not encontrada:
                print(f"‚ö†Ô∏è Ninguna columna encontrada para regla con preferida '{preferida}'")

    columnas_descartadas = [col for col in df.columns if col not in columnas_finales]

    print("‚úÖ Columnas conservadas:")
    print(columnas_finales)
    print("\nüóëÔ∏è Columnas eliminadas:")
    print(columnas_descartadas)

    return df[columnas_finales].copy()



if __name__ == "__main__":
    ###This is just for testing Purposes""""
    # Ruta al archivo CSV
    csv_path = "./data/processed/interim/X_tr.csv"
    

    df = pd.read_csv(csv_path, low_memory=False)
    print("\n‚úÖ DATOS ORGINALES:")
    print(df.shape)

    df_procesado = process_numerical_discrete(csv_path, encode=True, binning=True, normalize=True)

    print("\n‚úÖ DATOS PROCESADOS:")
    print(df_procesado.shape)
    


    # csv_path = Path("data-with-columns.csv")


    # Guardar resultado en archivo
    #df_procesado.to_csv("data-preprocessed.csv", index=False)
    print("\n‚úÖ Archivo preprocesado guardado como data-preprocessed.csv")
