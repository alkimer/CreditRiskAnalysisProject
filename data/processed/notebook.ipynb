{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Applies SMOTE to balance the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features\n",
    "        y (pd.Series or array): Target\n",
    "        random_state (int): Seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_resampled (pd.DataFrame), y_resampled (pd.Series)\n",
    "    \"\"\"\n",
    "    \n",
    "    sm = SMOTE(random_state=random_state)    # sampling_strategy=0.5)\n",
    "    \n",
    "    X_res, y_res = sm.fit_resample(X, y.values.ravel())\n",
    "    X_resampled = pd.DataFrame(X_res, columns=X.columns)\n",
    "    y_resampled = pd.Series(y_res, name=\"target\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def smotenc(X, y, categorical_features, random_state=42):\n",
    "    \"\"\"\n",
    "    Applies SMOTENC to balance the dataset with categorical features.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Features\n",
    "        y (pd.Series or array): Target\n",
    "        categorical_features (list): List of column indices (not names) that are categorical\n",
    "        random_state (int): Seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        X_resampled (pd.DataFrame), y_resampled (pd.Series)\n",
    "    \"\"\"\n",
    "    sm = SMOTENC(categorical_features=categorical_features, random_state=random_state)\n",
    "\n",
    "    X_res, y_res = sm.fit_resample(X.values, y.values.ravel())\n",
    "\n",
    "    X_resampled = pd.DataFrame(X_res, columns=X.columns)\n",
    "    y_resampled = pd.Series(y_res, name=\"target\")\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/aac/Anyone/FinalProject/CreditRiskAnalysisProject/\")\n",
    "\n",
    "X_train = pd.read_csv('data/processed/X_train_balanced.csv')\n",
    "\n",
    "print(len(X_train))\n",
    "\n",
    "print(\"Â¿Hay NaNs en X_train BALANCED?\")\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(X_train.isnull().sum().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_balanced = pd.read_csv('data/processed/y_train_balanced.csv')\n",
    "\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_balanced = pd.read_csv('data/processed/X_train_balanced.csv')\n",
    "\n",
    "print(X_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_by_segment(df_segmented):\n",
    "    \n",
    "    # Ensure the segment column exists\n",
    "    if 'kmeans_segment' not in df_segmented.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'kmeans_segment' column.\")\n",
    "    \n",
    "    # Identify numeric columns for statistics and plotting (excluding the segment column)\n",
    "    # numeric_cols = df_segmented.select_dtypes(include='number').drop(columns=['kmeans_segment'], errors='ignore').columns\n",
    "\n",
    "    segments = sorted(df_segmented['kmeans_segment'].unique())\n",
    "\n",
    "    # Loop through each segment and perform EDA\n",
    "    for segment_label in segments:\n",
    "        segment_data = df_segmented[df_segmented['kmeans_segment'] == segment_label]\n",
    "        \n",
    "        print(f\"\\n=== EDA for Segment '{segment_label}' ===\")\n",
    "        print(f\"Number of records: {segment_data.shape[0]}\")\n",
    "        print(\"\\nDescriptive Statistics:\")\n",
    "        print(segment_data.describe())\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(segment_data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title(f'Correlation Heatmap - Segment {segment_label}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution plots for each numeric variable\n",
    "        for col in df_segmented.columns:\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.histplot(segment_data[col], kde=True, bins=30)\n",
    "            plt.title(f'Distribution of {col} - Segment {segment_label}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_balanced.csv')\n",
    "X_val = pd.read_csv('X_val_p.csv')\n",
    "y_train = pd.read_csv('y_train_balanced.csv')\n",
    "y_val = pd.read_csv('y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_LABEL_BAD=1\n",
       "0                     29524\n",
       "1                     29524\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() #normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Aplicar SMOTE solo a los datos de entrenamiento\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m xtrain_balanceado, ytrain_balanceado \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensiones originales de ytrain:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[0;32m~/Anyone/FinalProject/risk/lib/python3.10/site-packages/imblearn/base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anyone/FinalProject/risk/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anyone/FinalProject/risk/lib/python3.10/site-packages/imblearn/base.py:101\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m     98\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m~/Anyone/FinalProject/risk/lib/python3.10/site-packages/imblearn/utils/_validation.py:571\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_strategy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m sampling_strategy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a float, it should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the range (0, 1]. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m         )\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m--> 571\u001b[0m             \u001b[43m_sampling_strategy_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    572\u001b[0m         )\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(sampling_strategy):\n\u001b[1;32m    575\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m sampling_strategy(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Anyone/FinalProject/risk/lib/python3.10/site-packages/imblearn/utils/_validation.py:410\u001b[0m, in \u001b[0;36m_sampling_strategy_float\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    405\u001b[0m         key: \u001b[38;5;28mint\u001b[39m(n_sample_majority \u001b[38;5;241m*\u001b[39m sampling_strategy \u001b[38;5;241m-\u001b[39m value)\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m target_stats\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m class_majority\n\u001b[1;32m    408\u001b[0m     }\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([n_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy_\u001b[38;5;241m.\u001b[39mvalues()]):\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified ratio required to remove samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the minority class while trying to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate new samples. Please increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m         )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    417\u001b[0m     n_sample_minority \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(target_stats\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "\n",
    "# Aplicar SMOTE solo a los datos de entrenamiento\n",
    "xtrain_balanceado, ytrain_balanceado = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Dimensiones originales de ytrain:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDimensiones de ytrain despuÃ©s de SMOTE:\")\n",
    "print(ytrain_balanceado.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/aac/Anyone/FinalProject/CreditRiskAnalysisProject/\")\n",
    "\n",
    "X_train = pd.read_csv('data/processed/interim/X_train_X_train_unbalanced.csv')\n",
    "X_val = pd.read_csv('data/processed/interim/X_val_X_val_unbalanced.csv')\n",
    "\n",
    "print(\"Â¿Hay NaNs en X_train?\")\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(X_train.isnull().sum().to_string())\n",
    "    print(\"\\n\\n\",\"-\"*20)\n",
    "    print(\"-- Now X_val --\")\n",
    "    print(\"\\n\")\n",
    "    print(X_val.isnull().sum().to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
