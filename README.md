# ğŸ§  Credit Risk Analysis Project

Este proyecto implementa un sistema completo de **anÃ¡lisis de riesgo crediticio**, combinando:

- ğŸ”Œ Una **API REST** construida con **FastAPI**
- ğŸ§µ Un motor de predicciÃ³n asincrÃ³nico usando **Redis**
- ğŸ—ƒ Una base de datos ligera basada en **SQLite**
- ğŸ–¥ Una interfaz de usuario intuitiva desarrollada en **Streamlit**
- ğŸ³ Todo completamente orquestado mediante **Docker Compose**

---

## ğŸš€ Â¿CÃ³mo ejecutar el proyecto?

ClonÃ¡ el repositorio y ejecutÃ¡:

```bash
docker compose up --build
```

Esto levantarÃ¡ todos los servicios necesarios: API, worker, Redis, base de datos y la UI.

---

## ğŸŒ Accesos

- **ğŸ§‘â€ğŸ’» Interfaz de Usuario (UI)**:  
  ğŸ‘‰ [http://localhost:8051](http://localhost:8051)

- **ğŸ“š DocumentaciÃ³n Interactiva de la API** (Swagger):  
  ğŸ‘‰ [http://localhost:8051/docs](http://localhost:8051/docs)

---

## ğŸ“¬ Ejemplos de uso vÃ­a API

### ğŸ” Obtener una predicciÃ³n

```bash
curl -X POST http://localhost:8000/model/predict \
  -H "Content-Type: application/json" \
  -d '{
    "MARITAL_STATUS": 1,
    "MONTHS_IN_RESIDENCE": 12,
    "AGE": 35,
    "OCCUPATION_TYPE": 1,
    "SEX": "M",
    "FLAG_RESIDENCIAL_PHONE": "Y",
    "STATE_OF_BIRTH": "BA",
    "RESIDENCIAL_STATE": "BA",
    "RESIDENCE_TYPE": 1,
    "PROFESSIONAL_STATE": "BA",
    "PRODUCT": "Personal Loan",
    "RESIDENCIAL_CITY": "BahÃ­a Blanca",
    "RESIDENCIAL_BOROUGH": "Centro",
    "RESIDENCIAL_PHONE_AREA_CODE": "291",
    "RESIDENCIAL_ZIP_3": "800",
    "PROFESSIONAL_ZIP_3": "800"
  }'
```

---

### ğŸ•“ Consultar historial de predicciones

```bash
curl -X GET http://localhost:8000/model/predictions
```

---

## ğŸ“¦ Estructura de servicios (Docker Compose)

| Servicio             | DescripciÃ³n                                  |
|----------------------|----------------------------------------------|
| `credit-risk-api`    | API REST con FastAPI                         |
| `credit-risk-worker` | Worker asincrÃ³nico con Redis                 |
| `credit-risk-redis`  | Servicio de cola de trabajos                 |
| `credit-risk-ui`     | Interfaz de usuario con Streamlit            |
| `sqlite`             | Base de datos ligera embebida                |



## Estructura del Proyecto

### `credit_risk_analysis/db/`
Contiene los scripts y componentes necesarios para la inicializaciÃ³n e interacciÃ³n con la base de datos. Actualmente se utiliza **SQLite** como motor de almacenamiento relacional, elegido por su simplicidad y compatibilidad con despliegues livianos en AWS (limitaciÃ³n impuesta por la imposibilidad de usar PostgreSQL en este entorno).

- `prediction_orm.py`: Define el modelo ORM para registrar y consultar predicciones realizadas.

---

### `credit_risk_analysis/api/`
Define los **endpoints REST** expuestos por el sistema para interactuar con el motor de predicciÃ³n. A travÃ©s de esta capa se reciben solicitudes externas para generar nuevas predicciones y consultar el historial existente.

- `router.py`: Contiene las rutas y controladores principales para los endpoints del sistema.

---

### `credit_risk_analysis/model/`
Incluye la lÃ³gica encapsulada del **modelo de machine learning**. Esta capa actÃºa como fachada hacia el pipeline de inferencia, cargando el modelo serializado y ejecutando la predicciÃ³n sobre los datos entrantes.

- `predict.py`: FunciÃ³n principal de predicciÃ³n, incluye validaciones y preprocesamiento.

---

### `models/`
Contiene los **artefactos del modelo serializado**, incluyendo tanto el pipeline de preprocesamiento como el modelo entrenado. Estos objetos son utilizados en tiempo de inferencia.

- `preprocessor.pkl`: Pipeline de preprocesamiento de datos.
- `stacking_model.pkl`: Modelo de machine learning serializado (Stacking Ensemble).

---

### `credit_risk_analysis/services/`
Define los **servicios asincrÃ³nicos** encargados de gestionar la cola de trabajos de predicciÃ³n mediante Redis. Este patrÃ³n desacopla el proceso de predicciÃ³n de la interfaz API, permitiendo un escalamiento mÃ¡s flexible.

- `prediction_job_producer.py`: Encola nuevas tareas de predicciÃ³n.
- `prediction_job_consumer.py`: Worker que consume tareas de Redis y ejecuta las predicciones.
- `schema.py`: Define esquemas y tipos usados entre componentes del servicio.

---

### `UI/`
Contiene la **interfaz de usuario desarrollada en Streamlit**, pensada para permitir interacciÃ³n sencilla con el sistema por parte de usuarios no tÃ©cnicos. Se pueden realizar predicciones manuales y visualizar resultados.

- `app.py`: Archivo principal de la aplicaciÃ³n Streamlit.
- `assets/`: Archivos estÃ¡ticos (CSS, imÃ¡genes, etc.)
- `logo_intro.css`: Estilos personalizados de la interfaz.

---

### `aws/`
Scripts de automatizaciÃ³n y configuraciÃ³n para despliegue del sistema en una instancia EC2 de AWS.

- `connect_aws.sh`: ConexiÃ³n por SSH a la instancia remota.
- `setup_env_aws.sh`: Configura el entorno en la instancia EC2 (Docker, dependencias, etc.).
- `subir_proyecto_aws.sh`: Sincroniza el proyecto local con la instancia EC2.

- `deploy_and_run_aws.sh`: Es el All-in-one, hace todo lo que hacen los anteriores.

---

## Despliegue

Todo el sistema estÃ¡ **dockerizado**. La ejecuciÃ³n completa de los servicios se realiza mediante:

```bash
docker compose up --build -d
```

Este comando levanta los siguientes contenedores:

- API REST
- Redis
- Base de datos SQLite
- Interfaz Streamlit

> âš ï¸ Nota: Debido a restricciones de red y almacenamiento en el entorno AWS Free Tier, se utiliza SQLite en lugar de PostgreSQL para simplificar el despliegue.

---

## TecnologÃ­as utilizadas

- Python 3.10+
- FastAPI
- Redis
- Streamlit
- Scikit-learn
- Docker / Docker Compose
- SQLite

---

## Estado del Proyecto

âœ… Funcional  
ğŸ”œ En futuras versiones se evaluarÃ¡ migrar la base de datos a PostgreSQL y escalar el sistema con Kubernetes para ambientes productivos.

---